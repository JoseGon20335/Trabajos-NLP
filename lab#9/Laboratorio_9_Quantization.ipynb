{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH_zPatjVVhE"
      },
      "source": [
        "NOMBRE: Jose Miguel Gonzalez\n",
        "\n",
        "\n",
        "CARNE: 20335\n",
        "\n",
        "\n",
        "FECHA:10/10/2024\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBAfJsqmZhWg"
      },
      "source": [
        "**Objetivo**: La idea de esta práctica es que exploren el desarrollo de un proceso de cuatización. Para esto, deben cubrir lo que se vio en clase:\n",
        "1. Efectuar el proceso de cuantización.\n",
        "2. Determinar su error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch import tensor\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Mt-KTIVrVt12"
      },
      "outputs": [],
      "source": [
        "#Así como se vio en clase, definan una proceso de linear quantization para test_tensor\n",
        "#Para llevar esto a acabo, debe encontrar la escala: scale = rmax-rmin/qmax-qmin.\n",
        "#Trabajando con pytorch int8 (para mapear a int4) qmax=127 y qmin=128.\n",
        "#zero_point = qmin-(rmin/scale).\n",
        "#Con esta informacion ya pueden proceder a trabaja la cuantización lineal.\n",
        "\n",
        "# Tensor inicial\n",
        "input_tensor = torch.tensor([[-0.6870,  0.2607, -0.7718,  0.0841],\n",
        "                             [ 0.6558, -1.1711, -1.0713,  0.2405],\n",
        "                             [ 1.4967, -0.6928,  0.7961, -1.4614],\n",
        "                             [ 0.5689, -0.5227, -1.3111, -0.8343]])\n",
        "\n",
        "target_quantized = torch.tensor([[-77, -77, -77, -77],\n",
        "                                 [-77, -77, -77, -77],\n",
        "                                 [-77, -77, -77, -77],\n",
        "                                 [-77, -77, -77, -77]], dtype=torch.int8)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensor Cuantizado:\n",
            "tensor([[ -61,   20,  -69,    5],\n",
            "        [  55, -103,  -94,   19],\n",
            "        [ 127,  -62,   67, -128],\n",
            "        [  47,  -47, -115,  -74]], dtype=torch.int8)\n"
          ]
        }
      ],
      "source": [
        "# Rango de int8\n",
        "min_val, max_val = -128, 127\n",
        "\n",
        "# Encontrar los valores mínimo y máximo del tensor\n",
        "min_real, max_real = input_tensor.min(), input_tensor.max()\n",
        "\n",
        "# Calcular la escala\n",
        "scaling_factor = (max_real - min_real) / (max_val - min_val)\n",
        "\n",
        "# Calcular el punto cero\n",
        "zero_offset = min_val - torch.round(min_real / scaling_factor)\n",
        "\n",
        "# Cuantización\n",
        "quantized_output = torch.round((input_tensor / scaling_factor) + zero_offset).to(torch.int8)\n",
        "\n",
        "print(\"Tensor Cuantizado:\")\n",
        "print(quantized_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor Descuantizado:\n",
            "tensor([[-0.6844,  0.2552, -0.7772,  0.0812],\n",
            "        [ 0.6612, -1.1716, -1.0672,  0.2436],\n",
            "        [ 1.4965, -0.6960,  0.8004, -1.4616],\n",
            "        [ 0.5684, -0.5220, -1.3108, -0.8352]])\n"
          ]
        }
      ],
      "source": [
        "# Descuantización\n",
        "restored_tensor = (quantized_output.to(torch.float32) - zero_offset) * scaling_factor\n",
        "\n",
        "print(\"\\nTensor Descuantizado:\")\n",
        "print(restored_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Error medio: 0.002495\n"
          ]
        }
      ],
      "source": [
        "# Error entre el tensor original y el descuantizado\n",
        "mean_error = torch.abs(input_tensor - restored_tensor).mean()\n",
        "print(f\"\\nError medio: {mean_error.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y2z0ujTYdgf"
      },
      "source": [
        "Con la parte anterior correcta, ya pueden proceder a trabajar lo siguiente:\n",
        "\n",
        "1. Investigar Symmetric mode quantization.\n",
        "2. per-channel quantization.\n",
        "3. per-group quantization.\n",
        "\n",
        "Para cada uno de estos, explicar su funcionamiento y cuando puede ser conveniente usarlos respecto a las otras técnicas.\n",
        "\n",
        "Finalmente, desarrollar cada uno de la misma manera en que se trabajo la cuantización lineal. (Estos tres son casos especiales de la cuantización lineal, por lo que deberían solo hacer cambios especificos al código de la primera parte).\n",
        "\n",
        "\n",
        "Responda la siguiente pregunta: ¿Aquí estamos trabajando post-training quantization o quantization-aware training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sobreescribir valores de cuantización\n",
        "quantized_output |= target_quantized\n",
        "\n",
        "# Definir un tensor de cero para descuantización\n",
        "reconstructed_tensor = torch.zeros_like(input_tensor)\n",
        "\n",
        "# Cuantización Simétrica\n",
        "sym_scale = (max_real - min_real) / (max_val - min_val)\n",
        "sym_zero_point = 0  # En modo simétrico\n",
        "\n",
        "quantized_symmetric = torch.round(input_tensor / sym_scale).to(torch.int8)\n",
        "\n",
        "restored_symmetric = quantized_symmetric.to(torch.float32) * sym_scale\n",
        "sym_error = torch.abs(input_tensor - restored_symmetric).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor Cuantizado (Modo Simétrico):\n",
            "tensor([[ -59,   22,  -67,    7],\n",
            "        [  57, -101,  -92,   21],\n",
            "        [-127,  -60,   69, -126],\n",
            "        [  49,  -45, -113,  -72]], dtype=torch.int8)\n",
            "\n",
            "Tensor Descuantizado (Modo Simétrico):\n",
            "tensor([[-0.6844,  0.2552, -0.7772,  0.0812],\n",
            "        [ 0.6612, -1.1716, -1.0672,  0.2436],\n",
            "        [-1.4732, -0.6960,  0.8004, -1.4616],\n",
            "        [ 0.5684, -0.5220, -1.3108, -0.8352]])\n",
            "Error medio (Simétrico): 0.188101\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTensor Cuantizado (Modo Simétrico):\")\n",
        "print(quantized_symmetric)\n",
        "print(\"\\nTensor Descuantizado (Modo Simétrico):\")\n",
        "print(restored_symmetric)\n",
        "print(f\"Error medio (Simétrico): {sym_error.item():.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cuantización por Canal\n",
        "channel_scales = (input_tensor.max(dim=0).values - input_tensor.min(dim=0).values) / (max_val - min_val)\n",
        "channel_zero_points = torch.zeros_like(channel_scales, dtype=torch.int8)\n",
        "\n",
        "quantized_channel = torch.round((input_tensor / channel_scales) + channel_zero_points).to(torch.int8)\n",
        "\n",
        "restored_channel = (quantized_channel.to(torch.float32) - channel_zero_points) * channel_scales\n",
        "channel_error = torch.abs(input_tensor - restored_channel).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor Cuantizado (Por Canal):\n",
            "tensor([[ -80,   46,  -93,   13],\n",
            "        [  77,   47,  126,   36],\n",
            "        [ -81, -123,   96,   37],\n",
            "        [  66,  -93,   97, -125]], dtype=torch.int8)\n",
            "\n",
            "Tensor Descuantizado (Por Canal):\n",
            "tensor([[-0.6851,  0.2583, -0.7685,  0.0868],\n",
            "        [ 0.6594,  0.2639,  1.0412,  0.2403],\n",
            "        [-0.6936, -0.6906,  0.7933,  0.2469],\n",
            "        [ 0.5652, -0.5222,  0.8016, -0.8343]])\n",
            "Error medio (Por Canal): 0.598887\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTensor Cuantizado (Por Canal):\")\n",
        "print(quantized_channel)\n",
        "print(\"\\nTensor Descuantizado (Por Canal):\")\n",
        "print(restored_channel)\n",
        "print(f\"Error medio (Por Canal): {channel_error.item():.6f}\")   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cuantización por Grupo\n",
        "group_a, group_b = input_tensor[:, :2], input_tensor[:, 2:]\n",
        "\n",
        "scale_a = (group_a.max() - group_a.min()) / (max_val - min_val)\n",
        "scale_b = (group_b.max() - group_b.min()) / (max_val - min_val)\n",
        "\n",
        "quantized_a = torch.round(group_a / scale_a).to(torch.int8)\n",
        "quantized_b = torch.round(group_b / scale_b).to(torch.int8)\n",
        "\n",
        "restored_a = quantized_a.to(torch.float32) * scale_a\n",
        "restored_b = quantized_b.to(torch.float32) * scale_b\n",
        "\n",
        "restored_group = torch.cat([restored_a, restored_b], dim=1)\n",
        "group_error = torch.abs(input_tensor - restored_group).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Tensor Cuantizado (Por Grupo):\n",
            "tensor([[ -66,   25,  -87,    9],\n",
            "        [  63, -112, -121,   27],\n",
            "        [-113,  -66,   90,   91],\n",
            "        [  54,  -50,  108,  -94]], dtype=torch.int8)\n",
            "\n",
            "Tensor Descuantizado (Por Grupo):\n",
            "tensor([[-0.6905,  0.2615, -0.7702,  0.0797],\n",
            "        [ 0.6591, -1.1717, -1.0712,  0.2390],\n",
            "        [-1.1822, -0.6905,  0.7968,  0.8056],\n",
            "        [ 0.5649, -0.5231,  0.9561, -0.8322]])\n",
            "Error medio (Por Grupo): 0.452403\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTensor Cuantizado (Por Grupo):\")\n",
        "print(torch.cat([quantized_a, quantized_b], dim=1))\n",
        "print(\"\\nTensor Descuantizado (Por Grupo):\")\n",
        "print(restored_group)\n",
        "print(f\"Error medio (Por Grupo): {group_error.item():.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Symmetric Mode Quantization: Usa una escala centrada en 0 sin punto cero adicional. Es más simple, ideal para datos simétricos, pero no es óptimo si los valores están desbalanceados.\n",
        "\n",
        "- Per-Channel Quantization: Ajusta la escala por canal, manteniendo mejor precisión en redes convolucionales donde cada canal tiene un rango diferente. Es más precisa pero aumenta la complejidad.\n",
        "\n",
        "- Per-Group Quantization: Agrupa canales para compartir una escala común, combinando precisión y simplicidad, especialmente útil en redes grandes con características agrupadas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "*¿Aquí estamos trabajando post-training quantization o quantization-aware training?*\n",
        "\n",
        "- Estamos trabajando con post-training quantization, ya que el modelo se cuantiza después de ser entrenado, sin incluir los efectos de la cuantización durante el entrenamiento."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
