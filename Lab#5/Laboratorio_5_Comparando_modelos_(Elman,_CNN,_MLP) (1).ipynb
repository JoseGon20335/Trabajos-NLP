{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M8Z1Z9foTP5"
      },
      "source": [
        "NOMBRE: Jose Miguel Gonzalez\n",
        "\n",
        "CARNE: 20335\n",
        "\n",
        "FECHA: 1/9/2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-xEM-4MoXO5"
      },
      "source": [
        "**Instrucciones:**\n",
        "El objetivo de esta práctica es que explorer la implementación del modelo de Elman. Además, para es para que puedan comparar como el rendimiento de este comparado con otras arquitecturas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lirH0vAapmS2"
      },
      "outputs": [],
      "source": [
        "#Datos\n",
        "from keras.datasets import imdb\n",
        "vocabulary_size = 10000\n",
        "max_review_length = 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qz5YyKRNpyiV",
        "outputId": "b8017c4f-151c-4dde-dcdf-38ef2af7f6cd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reseñas de entreno 25000\n",
            "Longitud de las primera y quinta reseñas 218 147\n",
            "Primera reseña [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
            "Primera etiqueta 1\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size)\n",
        "print('Reseñas de entreno', len(X_train))\n",
        "print('Longitud de las primera y quinta reseñas', len(X_train[0]) ,len(X_train[4]))\n",
        "print('Primera reseña', X_train[0])\n",
        "print('Primera etiqueta', y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QTzj5_ajsqiO"
      },
      "outputs": [],
      "source": [
        "#Librerias para los modelos\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, LSTM, SimpleRNN, Embedding, Flatten\n",
        "from keras.preprocessing import sequence\n",
        "from keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, InputLayer\n",
        "import numpy as np\n",
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vlAp7iFNqE0l"
      },
      "outputs": [],
      "source": [
        "#Prepare los batches de su data de entreno (padding) utilice el valor de max_review_length\n",
        "\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "zXesGdQ7rKjj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 2s 4ms/step - loss: 138.7633 - accuracy: 0.5014 - val_loss: 31.7102 - val_accuracy: 0.5030\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 11.8548 - accuracy: 0.5409 - val_loss: 5.3880 - val_accuracy: 0.4965\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 1s 3ms/step - loss: 2.4342 - accuracy: 0.5345 - val_loss: 2.3315 - val_accuracy: 0.4987\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1a58dd70c10>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Construya un modelo Feed Forward de MLP sin embedding\n",
        "# Construcción de un modelo Feed Forward de MLP sin embedding\n",
        "mlp_model = Sequential()\n",
        "mlp_model.add(InputLayer(input_shape=(max_review_length,)))\n",
        "mlp_model.add(Dense(128, activation='relu'))\n",
        "mlp_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "mlp_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "mlp_model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "l3VlJff8rujp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 15s 36ms/step - loss: 0.4172 - accuracy: 0.7874 - val_loss: 0.2856 - val_accuracy: 0.8786\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.1204 - accuracy: 0.9584 - val_loss: 0.3574 - val_accuracy: 0.8626\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 14s 36ms/step - loss: 0.0200 - accuracy: 0.9957 - val_loss: 0.4736 - val_accuracy: 0.8628\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1a58a236710>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Construya un modelo Feed Forward de MLP con embedding\n",
        "# Construcción de un modelo Feed Forward de MLP con embedding\n",
        "mlp_emb_model = Sequential()\n",
        "mlp_emb_model.add(Embedding(vocabulary_size, 32, input_length=max_review_length))\n",
        "mlp_emb_model.add(Flatten())\n",
        "mlp_emb_model.add(Dense(128, activation='relu'))\n",
        "mlp_emb_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "mlp_emb_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "mlp_emb_model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um8CVUMIr9YW"
      },
      "source": [
        "Responda: ¿De qué dimensión debería ser la capa convolucional para de una CNN para procesar texto?\n",
        "\n",
        "\n",
        "R:La dimensión de la capa convolucional en una CNN para procesar texto está determinada por el tamaño del filtro (kernel). En procesamiento de texto, los filtros suelen tener dimensiones (n_gram_size, embedding_dim), donde n_gram_size es el número de palabras (o tokens) que se quieren capturar en una sola operación de convolución y embedding_dim es la dimensión de la representación densa de las palabras (por ejemplo, 32 en el modelo que se ha construido).\n",
        "\n",
        "En tu código, se utiliza un tamaño de filtro de 3 (Conv1D(32, 3, padding='same', activation='relu')), lo que significa que la CNN está aprendiendo patrones en secuencias de 3 palabras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "8ZBkDeZ4ryjq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 12s 27ms/step - loss: 0.4535 - accuracy: 0.7732 - val_loss: 0.3197 - val_accuracy: 0.8610\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 10s 27ms/step - loss: 0.2194 - accuracy: 0.9139 - val_loss: 0.3156 - val_accuracy: 0.8672\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.1134 - accuracy: 0.9617 - val_loss: 0.3094 - val_accuracy: 0.8808\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1a585f90710>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Basandose en la respuesta anterior construya un modelo CNN\n",
        "cnn_model = Sequential()\n",
        "cnn_model.add(Embedding(vocabulary_size, 32, input_length=max_review_length))\n",
        "cnn_model.add(Conv1D(32, 3, padding='same', activation='relu'))\n",
        "cnn_model.add(GlobalMaxPooling1D())\n",
        "cnn_model.add(Dense(128, activation='relu'))\n",
        "cnn_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "cnn_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "cnn_model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B1fns_fKsJqX"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "391/391 [==============================] - 38s 94ms/step - loss: 0.6516 - accuracy: 0.6343 - val_loss: 0.6373 - val_accuracy: 0.6182\n",
            "Epoch 2/3\n",
            "391/391 [==============================] - 35s 90ms/step - loss: 0.5071 - accuracy: 0.7568 - val_loss: 0.4539 - val_accuracy: 0.7952\n",
            "Epoch 3/3\n",
            "391/391 [==============================] - 36s 93ms/step - loss: 0.3640 - accuracy: 0.8431 - val_loss: 0.4522 - val_accuracy: 0.7935\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x1a5dad742d0>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Construya un modelo de Elman (SimpleRNN) y resuelva el problema\n",
        "elman_model = Sequential()\n",
        "elman_model.add(Embedding(vocabulary_size, 32, input_length=max_review_length))\n",
        "elman_model.add(SimpleRNN(32))\n",
        "elman_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "elman_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "elman_model.fit(X_train, y_train, epochs=3, batch_size=64, validation_data=(X_test, y_test))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
